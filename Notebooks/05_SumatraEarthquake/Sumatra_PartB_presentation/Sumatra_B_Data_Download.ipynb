{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='padding: 0px ; background-size: cover ; border-radius: 5px ; height: 250px'>\n",
    "    <div style=\"float: right ; margin: 50px ; padding: 20px ; background: rgba(255 , 255 , 255 , 0.7) ; width: 50% ; height: 150px\">\n",
    "        <div style=\"position: relative ; top: 50% ; transform: translatey(-50%)\">\n",
    "            <div style=\"font-size: xx-large ; font-weight: 900 ; color: rgba(0 , 0 , 0 , 0.8) ; line-height: 100%\">Analysis of the 2004 Sumatra-Andaman earthquake</div>\n",
    "            <div style=\"font-size: large ; padding-top: 20px ; color: rgba(0 , 0 , 0 , 0.5)\">Part B: Data Download</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Authors:\n",
    "* Carl Tape ([@carltape](https://github.com/carltape))\n",
    "* Yongki Andita Aiman\n",
    "* Tomy Gunawan\n",
    "* Angel Ling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on *GEOS 626: Applied Seismology from Carl Tape*\n",
    "\n",
    "The goal of this notebook is to download and choose the right data for Part B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation for programming\n",
    "# Make sure to execute this cell first!\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                  # do not show warnings\n",
    "from obspy import read\n",
    "from obspy.core import read, UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "plt.rcParams['figure.figsize'] = 15,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up parameters for getting waveforms\n",
    "client = Client(\"IRIS\")\n",
    "t = UTCDateTime(\"2004-12-26T00:58:53.0\")   # origin time of Sumatra earthquake\n",
    "starttime = t-(1*24*60*60)                 # 1 day before the the origin time\n",
    "endtime = t+(9*24*60*60)                   # 9 days after the the origin time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the download time\n",
    "start = datetime.now()\n",
    "\n",
    "# Downloading waveform data from the station list 1, 2, and 3\n",
    "# Please comment out the list you want to download \n",
    "\n",
    "#sta_list = pd.read_csv('stationlist1.csv', sep=',',header=None)   # List 1 (AAK-HKT)\n",
    "#sta_list = pd.read_csv('stationlist2.csv', sep=',',header=None)   # List 2 (HNR-PFO)\n",
    "#sta_list = pd.read_csv('stationlist3.csv', sep=',',header=None)   # List 3 (PMSA-YSS)\n",
    "\n",
    "sta_fname = sta_list[1] # list of file name\n",
    "sta_code = sta_list[2]  # list of station code\n",
    "sta_chan = sta_list[3]  # list of SEED channel\n",
    "sta_loc = sta_list[4]   # list of SEED location\n",
    "sta_net = sta_list[5]   # list of station network\n",
    "\n",
    "# Download and save the raw waveform in a new directory\n",
    "directory = \"./data\"\n",
    "if not path.exists(directory):  # If data directory doesn't exist, it will create one\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(len(sta_code)):\n",
    "    st = client.get_waveforms(sta_net[i], sta_code[i], sta_loc[i], sta_chan[i],\n",
    "                              starttime, endtime, attach_response=True)     # get the waveform\n",
    "    st.resample(1.0)                                                        # resample the sampling rate\n",
    "    st.merge(method=1, fill_value=0)                                        # merge the traces, fill gaps with 0\n",
    "    st.write(path.join(directory, sta_fname[i]), format = 'SAC')    # write and save the stream into SAC format\n",
    "    print (st)\n",
    "\n",
    "# Print download time\n",
    "d = datetime.now() - start\n",
    "print (d, \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the downloaded signal\n",
    "sta_list = pd.read_csv('stationlist.csv', sep=',',header=None)\n",
    "sta_fname = sta_list[1]                        # list of file name\n",
    "str = read(path.join(directory, sta_fname[0])) # Enter the number of the station you want to check (start from 0)\n",
    "print (str)\n",
    "str.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform fft and save the result \n",
    "\n",
    "# stationlist.csv provides the full list of stations used in this exercise\n",
    "sta_list = pd.read_csv('stationlist.csv', sep=',',header=None)\n",
    "sta_fname = np.array(sta_list[1])\n",
    "directory = \"./data\"\n",
    "directory1 = \"./fft\"\n",
    "if not path.exists(directory1):\n",
    "    os.makedirs(directory1)\n",
    "\n",
    "nsec = 10*24*60*60    # convert 10 days into s\n",
    "npts = nsec * 1     # sampling rate is 1 Hz\n",
    "taper_percentage = 0.005\n",
    "taper = cosine_taper(nsec,taper_percentage)\n",
    "\n",
    "# Read and merge all data into single stream object\n",
    "# Perform tapering, detrending \n",
    "for i in range (len(sta_fname)):\n",
    "    st = read (path.join(directory, sta_fname[i]),header=None )\n",
    "    st_copy = st.copy()\n",
    "    tr = np.array(st_copy[0])\n",
    "    t = Trace(tr).stats.starttime\n",
    "    tr_trim = np.array(Trace(tr).trim(t,t+nsec-1, pad=True, fill_value=0)) # Make sure they have the same no. of sample\n",
    "    tr_taper = tr_trim * taper  \n",
    "    tr_detrend = detrend(tr_taper, 'linear')\n",
    "    tr_fft = Trace(np.array(np.fft.rfft(tr_detrend)))\n",
    "    tr_fft.write(path.join(directory1, sta_fname[i]), format = 'SAC')  # write and save the stream into \".sac\" format\n",
    "    print (tr_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spectra for mode analysis\n",
    "# We can use the station data when we see 5 peaks in the spectrogram\n",
    "\n",
    "sta_list = pd.read_csv('./stationlist.csv', sep=',',header=None)\n",
    "sta_fname = np.array(sta_list[1])\n",
    "directory = \"./data\"\n",
    "directory1 = \"./fft\"\n",
    "if not path.exists(directory1):\n",
    "    os.makedirs(directory1)\n",
    "    \n",
    "i = 10        # code number of station\n",
    "fNy = 1/2     # Nyquist Frequency is a half of sampling rate\n",
    "print('station:', sta_fname[i])\n",
    "st = read (path.join(directory1, sta_fname[i]),header=None )\n",
    "st_copy = st.copy()\n",
    "tr_fft_check = st_copy[0].data\n",
    "freq = (np.linspace(0, fNy, len(tr_fft_check)))*1000  # to get mHz\n",
    "\n",
    "#plot the spectrum\n",
    "plt.plot(freq, abs(tr_fft_check), lw=1)    \n",
    "plt.title('Amplitude spectrum')\n",
    "plt.xlabel('Frequency [mHz]')\n",
    "plt.ylabel('Amplitude [counts]')\n",
    "plt.xlim (0.26, 0.35)\n",
    "plt.ylim (0, 0.1E8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
